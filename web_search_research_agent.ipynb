{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-01T22:24:11.527149Z",
     "start_time": "2025-09-01T22:24:10.190982Z"
    }
   },
   "cell_type": "code",
   "source": "pip install tavily-python",
   "id": "7daa2f37fc429154",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tavily-python\n",
      "  Using cached tavily_python-0.7.11-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\parth\\pycharmprojects\\jupyterproject\\ai_agent\\.venv\\lib\\site-packages (from tavily-python) (2.32.5)\n",
      "Requirement already satisfied: tiktoken>=0.5.1 in c:\\users\\parth\\pycharmprojects\\jupyterproject\\ai_agent\\.venv\\lib\\site-packages (from tavily-python) (0.11.0)\n",
      "Requirement already satisfied: httpx in c:\\users\\parth\\pycharmprojects\\jupyterproject\\ai_agent\\.venv\\lib\\site-packages (from tavily-python) (0.28.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\parth\\pycharmprojects\\jupyterproject\\ai_agent\\.venv\\lib\\site-packages (from tiktoken>=0.5.1->tavily-python) (2025.8.29)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\parth\\pycharmprojects\\jupyterproject\\ai_agent\\.venv\\lib\\site-packages (from requests->tavily-python) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\parth\\pycharmprojects\\jupyterproject\\ai_agent\\.venv\\lib\\site-packages (from requests->tavily-python) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\parth\\pycharmprojects\\jupyterproject\\ai_agent\\.venv\\lib\\site-packages (from requests->tavily-python) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\parth\\pycharmprojects\\jupyterproject\\ai_agent\\.venv\\lib\\site-packages (from requests->tavily-python) (2025.8.3)\n",
      "Requirement already satisfied: anyio in c:\\users\\parth\\pycharmprojects\\jupyterproject\\ai_agent\\.venv\\lib\\site-packages (from httpx->tavily-python) (4.10.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\parth\\pycharmprojects\\jupyterproject\\ai_agent\\.venv\\lib\\site-packages (from httpx->tavily-python) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\parth\\pycharmprojects\\jupyterproject\\ai_agent\\.venv\\lib\\site-packages (from httpcore==1.*->httpx->tavily-python) (0.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\parth\\pycharmprojects\\jupyterproject\\ai_agent\\.venv\\lib\\site-packages (from anyio->httpx->tavily-python) (1.3.1)\n",
      "Using cached tavily_python-0.7.11-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: tavily-python\n",
      "Successfully installed tavily-python-0.7.11\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-01T22:24:19.237218Z",
     "start_time": "2025-09-01T22:24:17.627875Z"
    }
   },
   "source": [
    "##import required libraries\n",
    "import os\n",
    "from typing import Annotated\n",
    "from tavily import TavilyClient\n",
    "from autogen import AssistantAgent, UserProxyAgent, config_list_from_json, register_function\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-01T22:24:34.740757Z",
     "start_time": "2025-09-01T22:24:34.737107Z"
    }
   },
   "cell_type": "code",
   "source": [
    "config_list=[\n",
    "    {\"model\":\"Qwen3\",\n",
    "     \"base_url\":\"http://localhost:11434/v1\",\n",
    "     \"api_key\":\"ollama\",\n",
    "     \"price\":[0,0]},\n",
    "]\n",
    "llm_config={'config_list':config_list}"
   ],
   "id": "ee7599f8dc8114d4",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-01T22:24:41.139118Z",
     "start_time": "2025-09-01T22:24:41.133474Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tavily=TavilyClient(api_key=os.getenv('TAVILY_API_KEY'))\n",
    "\n",
    "def search_tool(query: Annotated[str, \"The search query\"])->Annotated[str, \"The search result\"]:\n",
    "    return tavily.get_search_context(query=query,search_depth=\"advanced\")"
   ],
   "id": "394bdc9067ca8ff8",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Adding ReAct prompt",
   "id": "53364c7f2a4197ef"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-01T22:25:02.270412Z",
     "start_time": "2025-09-01T22:25:02.265110Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ReAct_prompt=\"\"\"\n",
    "Answer the following question as best you can. You have access to tool provided.\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought:You should always think about what to do\n",
    "Action: the action to take\n",
    "Action Input: the input to the action\n",
    "Observation: the result to the action\n",
    "... (this process can repeat multiple times)\n",
    "Thought: I know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "\n",
    "Begin!\n",
    "Question:{input}\n",
    "\"\"\"\n",
    "\n",
    "#Define the ReAct prompt message. Assuming a \"question\" field is present in the context\n",
    "def react_prompt_message(sender, recipient, context):\n",
    "    return ReAct_prompt.format(input=context[\"question\"])"
   ],
   "id": "a37c075b97a7257f",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Define the Agent",
   "id": "7849d4cb5546fe9b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-01T22:25:16.490408Z",
     "start_time": "2025-09-01T22:25:16.283816Z"
    }
   },
   "cell_type": "code",
   "source": [
    "user_proxy=UserProxyAgent(\n",
    "    name=\"User\",\n",
    "    is_termination_msg=lambda x:x.get(\"content\",\"\") and x.get(\"content\",\"\").rstrip().endswith(\"TERMINATE\"),\n",
    "    human_input_mode=\"ALWAYS\",\n",
    "    max_consecutive_auto_reply=10,\n",
    "    code_execution_config=False\n",
    ")\n",
    "\n",
    "research_assistant=AssistantAgent(\n",
    "    name=\"Assistant\",\n",
    "    system_message=\"\"\"\n",
    "    You are a helpful research assistant who has the ability to search the web using the provided tools. Only use the tools you have been provided with. Reply TERMINATE when the task is done\"\"\",\n",
    "    llm_config=llm_config,\n",
    ")"
   ],
   "id": "61e96bf8b54281a0",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Register the Search Tool",
   "id": "e327729add2494f5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-01T22:25:31.032446Z",
     "start_time": "2025-09-01T22:25:30.848504Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Register the search tool.\n",
    "register_function(\n",
    "    search_tool,\n",
    "    caller=research_assistant,\n",
    "    executor=user_proxy,\n",
    "    name=\"Search_Tool\",\n",
    "    description=\"Search the web for the given query\",\n",
    ")"
   ],
   "id": "4bea6d9862dfdec0",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Initiate the chat",
   "id": "ef233dc323a31d61"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-01T22:30:03.455451Z",
     "start_time": "2025-09-01T22:28:50.132902Z"
    }
   },
   "cell_type": "code",
   "source": [
    "user_proxy.initiate_chats(\n",
    "    [\n",
    "        { \"recipient\":research_assistant,\n",
    "        \"messages\":react_prompt_message,\n",
    "        \"question\":\"Who won the T20 cricket world cup in 2024\"\n",
    "}\n",
    "]\n",
    "   )"
   ],
   "id": "7ee7073aee30b862",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m\n",
      "********************************************************************************\u001B[0m\n",
      "\u001B[34mStarting a new chat....\u001B[0m\n",
      "\u001B[34m\n",
      "********************************************************************************\u001B[0m\n",
      "\u001B[33mUser\u001B[0m (to Assistant):\n",
      "\n",
      "Who won the cricket world cup in 2019\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001B[33mAssistant\u001B[0m (to User):\n",
      "\n",
      "<think>\n",
      "Okay, the user is asking who won the 2019 cricket world cup. I need to find the correct answer. Let me think about the tools I have. There's the Search_Tool that can search the web. I should use that. The function requires a query parameter. The query here would be \"Who won the cricket world cup in 2019\". I'll call the Search_Tool with that query. Once I get the results, I can extract the information. From what I remember, England won in 2019, but I should confirm with the search tool to make sure. Alright, let's make the tool call.\n",
      "</think>\n",
      "\n",
      "\n",
      "\u001B[32m***** Suggested tool call (call_ym96qlgf): Search_Tool *****\u001B[0m\n",
      "Arguments: \n",
      "{\"query\":\"Who won the cricket world cup in 2019\"}\n",
      "\u001B[32m************************************************************\u001B[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001B[33mUser\u001B[0m (to Assistant):\n",
      "\n",
      "yes England won 2019 world cup\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001B[33mAssistant\u001B[0m (to User):\n",
      "\n",
      "<think>\n",
      "Okay, the user confirmed that England won the 2019 Cricket World Cup. Let me make sure that's correct. I remember from previous knowledge that the 2019 tournament was indeed won by England. They defeated Pakistan in the final. But wait, the user might want more details. Let me check if there's any additional information needed. The user's answer seems straightforward, but maybe they want to confirm or need the context of the match. Since the user already stated England won, and the tool response was interrupted, perhaps the user is satisfied. I should acknowledge their confirmation and maybe offer further assistance. Let me respond politely.\n",
      "</think>\n",
      "\n",
      "Great! England indeed won the 2019 ICC Cricket World Cup, defeating Pakistan in the final. Let me know if you'd like more details about the tournament! 🏏\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001B[31m\n",
      ">>>>>>>> TERMINATING RUN (eed7ef9a-904d-4aff-b7c2-917f2623668e): User requested to end the conversation\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ChatResult(chat_id=None, chat_history=[{'content': 'Who won the cricket world cup in 2019', 'role': 'assistant', 'name': 'User'}, {'content': '<think>\\nOkay, the user is asking who won the 2019 cricket world cup. I need to find the correct answer. Let me think about the tools I have. There\\'s the Search_Tool that can search the web. I should use that. The function requires a query parameter. The query here would be \"Who won the cricket world cup in 2019\". I\\'ll call the Search_Tool with that query. Once I get the results, I can extract the information. From what I remember, England won in 2019, but I should confirm with the search tool to make sure. Alright, let\\'s make the tool call.\\n</think>\\n\\n', 'tool_calls': [{'id': 'call_ym96qlgf', 'function': {'arguments': '{\"query\":\"Who won the cricket world cup in 2019\"}', 'name': 'Search_Tool'}, 'type': 'function', 'index': 0}], 'role': 'assistant'}, {'content': 'yes England won 2019 world cup', 'tool_responses': [{'role': 'tool', 'tool_call_id': 'call_ym96qlgf', 'content': 'USER INTERRUPTED'}], 'role': 'assistant', 'name': 'User'}, {'content': \"<think>\\nOkay, the user confirmed that England won the 2019 Cricket World Cup. Let me make sure that's correct. I remember from previous knowledge that the 2019 tournament was indeed won by England. They defeated Pakistan in the final. But wait, the user might want more details. Let me check if there's any additional information needed. The user's answer seems straightforward, but maybe they want to confirm or need the context of the match. Since the user already stated England won, and the tool response was interrupted, perhaps the user is satisfied. I should acknowledge their confirmation and maybe offer further assistance. Let me respond politely.\\n</think>\\n\\nGreat! England indeed won the 2019 ICC Cricket World Cup, defeating Pakistan in the final. Let me know if you'd like more details about the tournament! 🏏\", 'role': 'user', 'name': 'Assistant'}], summary=\"<think>\\nOkay, the user confirmed that England won the 2019 Cricket World Cup. Let me make sure that's correct. I remember from previous knowledge that the 2019 tournament was indeed won by England. They defeated Pakistan in the final. But wait, the user might want more details. Let me check if there's any additional information needed. The user's answer seems straightforward, but maybe they want to confirm or need the context of the match. Since the user already stated England won, and the tool response was interrupted, perhaps the user is satisfied. I should acknowledge their confirmation and maybe offer further assistance. Let me respond politely.\\n</think>\\n\\nGreat! England indeed won the 2019 ICC Cricket World Cup, defeating Pakistan in the final. Let me know if you'd like more details about the tournament! 🏏\", cost={'usage_including_cached_inference': {'total_cost': 0.0, 'Qwen3': {'cost': 0.0, 'prompt_tokens': 887, 'completion_tokens': 1009, 'total_tokens': 1896}}, 'usage_excluding_cached_inference': {'total_cost': 0.0, 'Qwen3': {'cost': 0.0, 'prompt_tokens': 887, 'completion_tokens': 1009, 'total_tokens': 1896}}}, human_input=['Who won the cricket world cup in 2019', 'yes England won 2019 world cup', 'exit'])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
